import cv2
import os
import numpy as np
from sklearn.model_selection import train_test_split

def verificar_calidad_imagenes():
    """Verificar y filtrar im√°genes de mala calidad"""
    dataPath = 'Data'
    total_removed = 0
    
    for person_name in os.listdir(dataPath):
        person_path = os.path.join(dataPath, person_name)
        if not os.path.isdir(person_path):
            continue
            
        print(f"üîç Verificando calidad de im√°genes para: {person_name}")
        removed_count = 0
        
        for image_file in os.listdir(person_path):
            if image_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                image_path = os.path.join(person_path, image_file)
                
                # Leer imagen
                img = cv2.imread(image_path, 0)
                if img is None:
                    os.remove(image_path)
                    removed_count += 1
                    continue
                
                # Verificar calidad (nitidez)
                blur_value = cv2.Laplacian(img, cv2.CV_64F).var()
                
                # Verificar tama√±o
                if img.shape[0] < 100 or img.shape[1] < 100:
                    os.remove(image_path)
                    removed_count += 1
                    continue
                
                # Verificar que no est√© muy borrosa
                if blur_value < 50:
                    os.remove(image_path)
                    removed_count += 1
                    continue
        
        remaining = len([f for f in os.listdir(person_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
        print(f"  ‚úÖ {person_name}: {remaining} im√°genes buenas, {removed_count} eliminadas")
        total_removed += removed_count
    
    print(f"üóëÔ∏è Total de im√°genes de mala calidad eliminadas: {total_removed}")

def obtenerModelo():
    """Obtener datos de entrenamiento con validaci√≥n"""
    dataPath = 'Data'
    peopleList = os.listdir(dataPath)
    print('üéØ Personas en base de datos:', peopleList)
    
    labels = []
    facesData = []
    label = 0
    
    for nameDir in peopleList:
        personPath = os.path.join(dataPath, nameDir)
        
        if not os.path.isdir(personPath):
            continue
            
        print(f'üìñ Procesando im√°genes de: {nameDir}')
        
        images = [f for f in os.listdir(personPath) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        if len(images) == 0:
            print(f"‚ö†Ô∏è Advertencia: No hay im√°genes en {personPath}")
            continue
        
        person_faces = []
        
        for fileName in images:
            img_path = os.path.join(personPath, fileName)
            img = cv2.imread(img_path, 0)
            
            if img is not None:
                # Redimensionar todas las im√°genes al mismo tama√±o
                img_resized = cv2.resize(img, (150, 150), interpolation=cv2.INTER_CUBIC)
                
                # Normalizar la imagen
                img_normalized = cv2.equalizeHist(img_resized)
                
                person_faces.append(img_normalized)
                labels.append(label)
        
        facesData.extend(person_faces)
        print(f"  ‚úÖ {len(person_faces)} im√°genes procesadas para {nameDir}")
        label += 1
    
    return facesData, labels

def entrenar_modelo_avanzado():
    """Entrenar modelo con validaci√≥n cruzada"""
    print('üöÄ ENTRENADOR AVANZADO DE RECONOCIMIENTO FACIAL')
    print('='*60)
    
    # Verificar calidad de im√°genes primero
    verificar_calidad_imagenes()
    
    # Obtener datos
    faces, labels = obtenerModelo()
    
    if len(faces) == 0:
        print("‚ùå Error: No se encontraron im√°genes v√°lidas para entrenar")
        return
    
    # Estad√≠sticas
    unique_labels = len(set(labels))
    print(f"üìä Estad√≠sticas del dataset:")
    print(f"   ‚Ä¢ Total de im√°genes: {len(faces)}")
    print(f"   ‚Ä¢ N√∫mero de personas: {unique_labels}")
    print(f"   ‚Ä¢ Promedio por persona: {len(faces)//unique_labels}")
    
    if len(faces) < 100:
        print("‚ö†Ô∏è ADVERTENCIA: Tienes pocas im√°genes. Recomendado: 200+ por persona")
        response = input("¬øContinuar de todos modos? (s/n): ")
        if response.lower() != 's':
            return
    
    # Dividir datos para validaci√≥n
    X_train, X_test, y_train, y_test = train_test_split(
        faces, labels, test_size=0.2, random_state=42, stratify=labels
    )
    
    print(f"üìö Datos de entrenamiento: {len(X_train)} im√°genes")
    print(f"üß™ Datos de prueba: {len(X_test)} im√°genes")
    
    # Crear y entrenar reconocedor
    print("\nü§ñ Entrenando modelo...")
    face_recognizer = cv2.face.LBPHFaceRecognizer_create(
        radius=2,          # M√°s preciso
        neighbors=16,      # M√°s vecinos para mejor precisi√≥n
        grid_x=8,         # Mayor resoluci√≥n
        grid_y=8,
        threshold=80.0     # Umbral m√°s alto para ser m√°s estricto
    )
    
    face_recognizer.train(X_train, np.array(y_train))
    
    # Validar modelo
    print("üß™ Validando modelo...")
    correct_predictions = 0
    total_predictions = len(X_test)
    
    confidences = []
    
    for i, (test_face, true_label) in enumerate(zip(X_test, y_test)):
        predicted_label, confidence = face_recognizer.predict(test_face)
        confidences.append(confidence)
        
        if predicted_label == true_label:
            correct_predictions += 1
    
    accuracy = (correct_predictions / total_predictions) * 100
    avg_confidence = np.mean(confidences)
    
    print(f"üìà Resultados de validaci√≥n:")
    print(f"   ‚Ä¢ Precisi√≥n: {accuracy:.1f}%")
    print(f"   ‚Ä¢ Confianza promedio: {avg_confidence:.1f}")
    print(f"   ‚Ä¢ Predicciones correctas: {correct_predictions}/{total_predictions}")
    
    # Determinar umbral recomendado
    if accuracy > 90:
        recommended_threshold = int(avg_confidence * 1.2)
        print(f"‚úÖ Modelo excelente. Umbral recomendado: {recommended_threshold}")
    elif accuracy > 75:
        recommended_threshold = int(avg_confidence * 1.5)
        print(f"‚ö†Ô∏è Modelo aceptable. Umbral recomendado: {recommended_threshold}")
    else:
        recommended_threshold = int(avg_confidence * 2.0)
        print(f"‚ùå Modelo pobre. Necesitas m√°s/mejores im√°genes. Umbral: {recommended_threshold}")
    
    # Guardar modelo
    model_path = 'FacesModel.xml'
    face_recognizer.write(model_path)
    
    # Guardar configuraci√≥n recomendada
    config_path = 'model_config.txt'
    with open(config_path, 'w') as f:
        f.write(f"recommended_threshold={recommended_threshold}\n")
        f.write(f"accuracy={accuracy:.1f}\n")
        f.write(f"avg_confidence={avg_confidence:.1f}\n")
        f.write(f"total_images={len(faces)}\n")
    
    print(f"\n‚úÖ Modelo guardado como: {model_path}")
    print(f"‚öôÔ∏è Configuraci√≥n guardada en: {config_path}")
    print('üéâ Entrenamiento completado!')
    
    return recommended_threshold

if __name__ == "__main__":
    entrenar_modelo_avanzado()